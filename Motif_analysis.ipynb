{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt \n",
      "import pandas as pd\n",
      "import re\n",
      "import cmath\n",
      "import math\n",
      "import glob\n",
      "import subprocess\n",
      "%matplotlib inline\n",
      "import matplotlib\n",
      "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "HOMER - "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# *** INPUT : Sample to process.\n",
      "sampleName='ddx21_dev'\n",
      "outfilepath=os.getcwd()+'/results/%s/'%sampleName\n",
      "clipperClusters=glob.glob(outfilepath+'*threshold*mergedRT_CLIP_clusters_cleaned.bed')[0]\n",
      "print \"Cluster file to process: %s\"%clipperClusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/arrayAhome/lmartin/CLIP/results/ddx21_dev/ddx21_dev_threshold=7_hg19_allreads.mergedRT_CLIP_clusters_cleaned.bed\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Note that we can also read from a custom HOMER read list: SourceData_HOMER_Custom\n",
      "geneLists=['PlotData_ExclusiveBound_5p','PlotData_ExclusiveBound_3p','PlotData_ExclusiveBound_cds','PlotData_ExclusiveBound_Intronic']\n",
      "UTRclusters=[]\n",
      "for geneList in geneLists:\n",
      "    path=outfilepath+geneList\n",
      "    print \"UTR file to process: %s\"%path\n",
      "    clusters=extractClusters(path,clipperClusters)\n",
      "    UTRclusters=UTRclusters+[clusters]\n",
      "\n",
      "# - Run HOMER on all clusters  - \n",
      "runHOMER(clipperClusters,'homer_allReads')\n",
      "\n",
      "'''\n",
      "shuffledReads=shuffleBedFile(clipperClusters)\n",
      "runHOMER(shuffledReads,'homer_allReads_shuffle')\n",
      "# - Run HOMER on clusters associated with gene lists that show region specific binding - \n",
      "folderNames=['homer_5pUTR','homer_3pUTR','homer_CDS','homer_intronic']\n",
      "i=0\n",
      "for clusterFile in UTRclusters:\n",
      "    runHOMER(clusterFile,folderNames[i])\n",
      "    i+=1\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# - Functions for extracting cluster data associated with gene list - \n",
      "def grep(pattern,filein):\n",
      "    # Usage: Open a file and search all lines for a pattern.\n",
      "    # Input: Pattern to search (gene name) and file name.\n",
      "    # Output: List of lines in a file that have the pattern.\n",
      "    r = []\n",
      "    filein_open = open(filein, 'r')\n",
      "    for line in filein_open:\n",
      "         # print line\n",
      "         if re.search(pattern,line):\n",
      "            r.append(line)\n",
      "    filein_open.close()\n",
      "    return r\n",
      "\n",
      "def extractClusters(geneList,allClusters):\n",
      "    # Usage: Extract a set of CLIPper clusters based on gene name\n",
      "    # Input: Gene list\n",
      "    # Output: Clusters with those genes\n",
      "    extractedClusters = geneList+'clusters.bed'\n",
      "    outfh = open(extractedClusters, 'w')\n",
      "\t# Iterate through each gene name\n",
      "    namesToQuery = np.genfromtxt(geneList,usecols=(0,),delimiter='\\t',dtype='string')\n",
      "    for name in namesToQuery:\n",
      "        # Grep it to the output \n",
      "        store=grep(name.strip(),allClusters)\n",
      "        # If NOT empty, then write to output\n",
      "        if store:\t\t\t\t\n",
      "            outfh.write(''.join(store))\n",
      "    outfh.close()\n",
      "    return extractedClusters\n",
      "\n",
      "# - Functions for running HOMER analysis - \n",
      "def shuffleBedFile(inBed):\n",
      "\t# Usage: Shuffle a bed file (usually used a background file for HOMER analysis) \n",
      "\t# Input: Bedfile\n",
      "\t# Output: SHuffled bedFile\n",
      "\tprogram = 'shuffleBed'\n",
      "\treferenceFile = os.getcwd()+'/docs/hg19_transcriptome_collapse_exon.bed'\n",
      "\tgenomeFile = os.getcwd()+'/docs/human.hg19.genome'\n",
      "\ttry:\n",
      "\t\tshuffledBed = inBed.replace('.bed','_shuffled.bed')\n",
      "\t\toutfh = open(shuffledBed, 'w')\n",
      "\t\tproc = subprocess.Popen([program,'-i',inBed,'-incl',referenceFile,'-g',genomeFile],stdout=outfh)\n",
      "\t\tproc.communicate()\n",
      "\t\treturn shuffledBed\n",
      "\texcept:\n",
      "\t\tprint \"Problem generating shuffled bedfile.\"\n",
      "        \n",
      "def makeBedForHOMER(inBed):\n",
      "    # Usage: This modified the bedfile for processing homer by making the first field a concatenation of chr_start_end\n",
      "\t# Input: Clean bedfile with first 5 field properly assigned\n",
      "\t# Output: Modified bed file with first field chr_start_end, and name excluded \n",
      "    try:\n",
      "        # Make sure bedfile only has 5 fields\n",
      "        print inBed\n",
      "        bedForHOMER=inBed.replace('.bed','_forHOMER.bed')\t\n",
      "        print bedForHOMER\n",
      "        # Open new file\n",
      "        f = open(bedForHOMER, 'w')\n",
      "        with open(inBed, 'r') as infile:\n",
      "            for line in infile:\t\n",
      "                elementList = line.strip().split('\\t')\n",
      "                # Re-write the bed file with chr replaced\n",
      "                f.write('\\t' .join((elementList[0]+'_'+elementList[1]+'_'+elementList[2],elementList[0],elementList[1],elementList[2],elementList[5],'\\n')))\n",
      "        f.close()\n",
      "        return bedForHOMER\n",
      "    except:\n",
      "        print \"Error making bed file for HOMER.\"\n",
      "\n",
      "def runHOMER(inBed,outDirName):\n",
      "\t# Usage: Run the HOMER motif finding algorithm \n",
      "\t# Input: Bedfile properly modified for HOMER\n",
      "\t# Output: A directory containing the HOMER output files\n",
      "    program='findMotifsGenome.pl'\n",
      "    program2='annotatePeaks.pl'\n",
      "    homerReferenceFile = os.getcwd()+'/docs/hg19_transcriptome_collapse_exon.bed'\n",
      "    # Convert the input bedFile into HOMER compatible format\n",
      "    inBedForHOMER=makeBedForHOMER(inBed)\n",
      "    # Get the path of the input file \n",
      "    path,filename=os.path.split(inBedForHOMER)\n",
      "    outDir=path+'/'+outDirName\n",
      "    # Call HOMER, which will generate a directory of files\n",
      "    proc = subprocess.Popen([program,inBedForHOMER,'hg19',outDir,'-rna','-bg',homerReferenceFile])\n",
      "    proc.communicate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Custom gene extraction - "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# *** INPUT : Sample to process.\n",
      "sampleName='ddx21_dev'\n",
      "# *** INPUT : Start of region to extract.\n",
      "start=1\n",
      "# *** INPUT : End of region to extract.\n",
      "end=199\n",
      "# Extract all reads in the region of interest\n",
      "outfilepath=os.getcwd() + '/results/%s/'%sample\n",
      "pathToCustomFile=customGeneExtraction(outfilepath,start,end)\n",
      "# Plot the region\n",
      "plotExtractedRegion(sample,1,start,end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run HOMER\n",
      "clipperClusters=outfilepath+sampleName+'_allreads.mergedRT_CLIP_clusters_cleaned.bed'\n",
      "outfilepath=os.getcwd()+'/results/%s/'%sampleName\n",
      "clipperClusters=glob.glob(outfilepath+'*threshold*mergedRT_CLIP_clusters_cleaned.bed')[0]\n",
      "print clipperClusters\n",
      "clusters=extractClusters(pathToCustomFile,clipperClusters)\n",
      "runHOMER(clusters,'homer_custom')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertENBLids(inNames):\n",
      "\t# Usage: Converl ENST to ENSG (unique ID) using ENSEMBL annotation file\n",
      "\t# Input: List of ENST IDs\n",
      "\t# Output: List of ENSG IDs\n",
      "\tgenesFile = os.getcwd() + '/docs/hg19_ensembl_genes.txt'\n",
      "\tensemblIDfile=np.genfromtxt(genesFile,usecols=(1,12,),delimiter='\\t',dtype='string') # Note that column lookup is zero indexed\n",
      "\ttemp=[]\n",
      "\tfor name in inNames:\n",
      "\t\toutName=ensemblIDfile[ensemblIDfile[:,0]==name,1]\n",
      "\t\ttemp=temp+[outName]\n",
      "\ttemp=np.array(temp)\n",
      "\treturn temp\n",
      "\n",
      "def customGeneExtraction(outfilepath,startIndex,endIndex):\n",
      "    # Extract genes with reads that fall within a specificied window \n",
      "    # Input: File path, and coordinates for data selection\n",
      "    # Output: None\n",
      "    \n",
      "    # Extract data from treat matrix\n",
      "    treatMatrixCols=600\n",
      "    treatMatrix=glob.glob(outfilepath+'*treatmatrix.txt')[0]\n",
      "    treatMatrixData=np.genfromtxt(treatMatrix,skip_header=1,usecols=range(1,treatMatrixCols+1),delimiter='\\t',dtype='float')\n",
      "    geneNames=np.loadtxt(treatMatrix,dtype='string',skiprows=1,usecols=(0,),delimiter='\\t')\n",
      "    print geneNames[0:10]\n",
      "    # pathToNameConversion=os.getcwd() + '/docs/refSeq_to_Ensl_all.txt'\n",
      "    # nameConversionToEnsembl=np.genfromtxt(pathToNameConversion,usecols=(0,1,),delimiter='\\t',dtype='string') # Note that column lookup is zero indexed\n",
      "    \n",
      "    # Convert to ENSG IDs and check for genes in the initial list \n",
      "    geneNames=convertENBLids(geneNames)\n",
      "    masterList = outfilepath+'clipGenes_proteinCoding'\n",
      "    masterNames = np.genfromtxt(masterList,usecols=(0,),delimiter='\\t',dtype='string') # Gene names isolated from Figure 1e\n",
      "    indexer=[]\n",
      "    for geneName in geneNames:\n",
      "        if geneName in masterNames:\n",
      "            indexer=indexer+[1]\n",
      "        else:\n",
      "            indexer=indexer+[0]\n",
      "    indexer=np.array(indexer,dtype=bool)\n",
      "    geneNames=geneNames[indexer]\n",
      "    treatMatrixData=treatMatrixData[indexer,:]\n",
      "    \n",
      "    customData=treatMatrixData[treatMatrixData[:,range(startIndex,endIndex+1)].sum(axis=1) > 0,:]\n",
      "    customNames=geneNames[treatMatrixData[:,range(startIndex,endIndex+1)].sum(axis=1) > 0]\n",
      "    \n",
      "    tosave=outfilepath+'TEMP'\n",
      "    np.savetxt(tosave,customData,fmt=\"%s\")\n",
      "    \n",
      "    treatSums=customData.sum(axis=1)\n",
      "    sortedIndex=list(reversed([i[0] for i in sorted(enumerate(treatSums),key=lambda x:x[1])]))\n",
      "    sortedData=customData[sortedIndex,:]\n",
      "    sortedNames=customNames[sortedIndex]\n",
      "    tosave=outfilepath+'SourceData_CustomGeneExtraction'\n",
      "    np.savetxt(tosave,np.unique(sortedNames),fmt=\"%s\")\n",
      "    return tosave\n",
      "\n",
      "def plotExtractedRegion(sample,plotNum,start,end):\n",
      "    outfilepath=os.getcwd() + '/results/%s/'%sample\n",
      "    # Bed file with protein coding reads\n",
      "    filteredProteinCoding = outfilepath+'clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved.bed'\n",
      "    averageGraph=outfilepath+'clipGenes_proteinCoding_LowFDRreads_centerCoord_snoRNAremoved_miRNAremoved_cleaned_sorted_UTRs_scaled_cds200_abt0_averageGraph.txt'\n",
      "    # Number of columns \n",
      "    avgGraphCols=600\n",
      "    avgGraphData=np.loadtxt(averageGraph,skiprows=1,dtype='float',usecols=range(1,avgGraphCols+1))\n",
      "    plt.subplot(1,2,plotNum)\n",
      "    ylimit=max(avgGraphData[1,:])*1.1\n",
      "    plt.plot(avgGraphData[1,:],color='blue',linewidth='2')\n",
      "    plt.ylim(0,ylimit)\n",
      "    plt.vlines(200,0,ylimit,linestyles='dashed')\n",
      "    plt.vlines(400,0,175,linestyles='dashed')\n",
      "    plt.tick_params(axis='x',labelbottom='off') \n",
      "    plt.axvspan(start,end,facecolor='r',alpha=0.5)\n",
      "    plt.tick_params(axis='y',labelsize=5) \n",
      "    plt.title(sample)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}